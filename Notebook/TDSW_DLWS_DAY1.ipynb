{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TDSW_DLWS_DAY1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-PbhdwiCB_o"
      },
      "source": [
        "# 準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaPDl5KJiZUV"
      },
      "source": [
        "## GPUを使えるようにする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GHanLRUidlF"
      },
      "source": [
        "1. メニューから `Runtime>Change runtime type` を選択する\n",
        "2. Hardware acceleratorでGPUを選択する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6VCXIsBjfD5"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqGtrQT_21Cs"
      },
      "source": [
        "## Google driveのマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXOfM3dYJTDr"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJWlwoR3AB2F"
      },
      "source": [
        "## Google Drive上でのディレクトリ作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOryyrx5-rQp"
      },
      "source": [
        "コマンドは `% + コマンド` で実現していきます．\n",
        "\n",
        "Google Driveのルートディレクトリである　`/content/drive/MyDrive`  に移動します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-02BP0_gJnbP"
      },
      "source": [
        "%cd /content/drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8TWP6ihAAUI"
      },
      "source": [
        "```\n",
        "MyDrive\n",
        "|--TDSW_DLWS\n",
        "    |--ImageClassifier\n",
        "        |--models\n",
        "```\n",
        "という構造でディレクトリを作成します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KxMBs9mKPhk"
      },
      "source": [
        "%mkdir TDSW_DLWS TDSW_DLWS/ImageClassifier/ TDSW_DLWS/ImageClassifier/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E43aUZihA84Y"
      },
      "source": [
        "ディレクトリを移動します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLgRrzdJKVfg",
        "outputId": "1a7758ed-1831-402f-ea6a-2abf5fd1e9cf"
      },
      "source": [
        "%cd TDSW_DLWS/ImageClassifier/models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/TDSW_DLWS/ImageClassifier/models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZHQUtQEBR8J"
      },
      "source": [
        "# 学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiPlG55VBpIe"
      },
      "source": [
        "## ライブラリのインポート\n",
        "必要なライブラリ，モジュールを読み込みます．  \n",
        "それぞれの機能については実際に使用する段階で説明します．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3i0WFLhTopj"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Input, Flatten, Conv2D, Dense, BatchNormalization, LeakyReLU, Dropout, Activation, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ducJEVoO5wRA"
      },
      "source": [
        "## データセットの読み込み＋前処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71kCUUrNNLT_"
      },
      "source": [
        "### CIFAR-10（画像とラベル）の読み込み\n",
        "CIFAR-10データセットを読み込みます．\n",
        "これは下の図のような60,000枚の32x32pxのRGB画像とそのラベル（どのクラスに属するか）のセットです．\n",
        "\n",
        "</br>\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1iHrBQSOBeOHNC9bMZc12IXhdtZk-ihM6\" width = 50%>\n",
        "\n",
        "</br>\n",
        "\n",
        "CIFAR-10などはKerasに同封されているためサクッと読み込めます．\n",
        "\n",
        "- x_train: 入力する訓練データ\n",
        "- x_test: テスト用データ\n",
        "- y_train: x_trainの各観測が属するクラス0 -- 9\n",
        "- y_test: x_testの各観測が属するクラス0 -- 9\n",
        "- cifar10.load_data(): データを読み込む関数\n",
        "\n",
        "データセットは訓練用とテスト用に分ける必要があります．\n",
        "\n",
        "訓練時には見せず，**未知のデータに対して推論できているかどうか確かめる**ためです．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiAHp04jwI1A"
      },
      "source": [
        "NUM_CLASSES = 10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yB9ptk-60hY",
        "outputId": "125edd8d-a957-49a3-cd16-ac6810d3ff20"
      },
      "source": [
        "print(x_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na2pAalN79hu"
      },
      "source": [
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHjYKFbW5kyi"
      },
      "source": [
        "### 0 - 255を0.0 - 1.0の32bit floatに変換\n",
        "ニューラルネットワークの入力は-1.0 -- 1.0で最も機能するため，割り算します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnF-bNXe4xTn"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss3SRcmf6tlI"
      },
      "source": [
        "### one-hotエンコーディング\n",
        "ラベルデータは，\n",
        "\n",
        "- 'airplane': 0\n",
        "- 'automobile': 1\n",
        "- 'bird': 2\n",
        "- 'cat': 3\n",
        "\n",
        "のようになっていますが，**クラス名と数字の大小は本来関係がありません**．  \n",
        "この大小関係を持ち込まないために，正解が1でそれ以外ゼロのベクトルに変更します．  \n",
        "ある画像のラベルが2番目（値は1）の場合:  \n",
        "`[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]`\n",
        "\n",
        "10クラスあるので，ベクトルの形状は`[50000, 1]`から`[50000, 10]`に変化します．  \n",
        "\n",
        "</br>\n",
        "\n",
        "関数はto_categorical(データ, クラス数)を使用します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TwXGwRD5b5d"
      },
      "source": [
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOHkkUI6mxQw"
      },
      "source": [
        "### データの水増し(今回は割愛)\n",
        "モデルの精度を高めるためにデータセットの画像に反転，回転，拡大縮小などの処理を加えてデータセットの数を増やします．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn5jwYJwo9_A"
      },
      "source": [
        "# データの水増し\n",
        "gen = ImageDataGenerator(rotation_range = 20, horizontal_flip = True, height_shift_range = 0.2, width_shift_range = 0.2,zoom_range = 0.2, channel_shift_range = 0.2)\n",
        "train_gen = gen.flow(x_train, y_train, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQxzctq3m224"
      },
      "source": [
        "## アーキテクチャのセットアップ\n",
        "Sequentialモデルではなく，より自由度の高いFunctional APIにて設計していきます．  \n",
        "あまり記述量も変わらないので，最初からFunctional APIで実装していくことをおすすめします．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKW25kF0Cgy5"
      },
      "source": [
        "### 入力層\n",
        "入力層には任意の枚数の画像を渡します．  \n",
        "shapeは入力の次元数を示しています．  \n",
        "実際の入力はもう１次元あるのですが，バッチサイズは任意の枚数であるため，指定していません．  \n",
        "バッチサイズについてはのちほど説明します．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3PLJJnSCffJ"
      },
      "source": [
        "input_layer = Input(shape = (32, 32, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rQ20YR1L6H_"
      },
      "source": [
        "### 畳み込み層\n",
        "Conv2Dで畳み込み層を設計します．\n",
        "kernel_size: カーネル（フィルタ）の縦横幅  \n",
        "strides: 画像をスキャンするときのステップサイズ  \n",
        "padding: sameの場合，畳み込み時にできる元画像の空白をゼロで埋める  \n",
        "\n",
        "### Pooling層\n",
        "MaxPooling2Dで小さい領域の最大値を選択します．\n",
        "pool_size: 少領域の縦横幅\n",
        "\n",
        "### 活性化関数\n",
        "活性化関数はニューラルネットが複雑な機能を学習し，単なる線形な組み合わせを出力しないように重みなどに掛け合わされて伝搬の具合に変化を与えます．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_NJiAiwq6gM"
      },
      "source": [
        "x = Conv2D(filters=32, kernel_size=3, strides=1, padding='same')(input_layer)\n",
        "x = LeakyReLU()(x)\n",
        "\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = LeakyReLU()(x)\n",
        "\n",
        "x = Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(x)\n",
        "x = LeakyReLU()(x)\n",
        "\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = LeakyReLU()(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDeH3OSG56Us"
      },
      "source": [
        "### 平滑化層\n",
        "最終的な出力であるそれぞれのクラスである確率１次元であるため，平滑化してベクトルにします．\n",
        "\n",
        "### Dropout層\n",
        "出力をしていした割合ゼロにしてしまうことで，過学習（持っているデータで学習しすぎた結果，未知の問題にうまく対応できない状態）を防ぎます．\n",
        "\n",
        "### 全結合層\n",
        "前の層と密結合したノードを指定の数持てます．  \n",
        "今回はクラスの分類を行なうためノードの数はクラス数となります．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ik8vJZ6L1fl"
      },
      "source": [
        "x = Flatten()(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = Dropout(rate=0.25)(x)\n",
        "\n",
        "x = Dense(NUM_CLASSES)(x)\n",
        "\n",
        "# 出力層を活性化関数softmax（総和１，他クラス分類問題に良い）\n",
        "output_layer = Activation('softmax')(x)\n",
        "\n",
        "# モデルとして宣言\n",
        "model = Model(input_layer, output_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JCe7xb__-Zg"
      },
      "source": [
        "### アーキテクチャの確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VJewd1V_9is"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgEX0yFHn8lD"
      },
      "source": [
        "## モデルのコンパイル\n",
        "普段聞くコンパイルは，  \n",
        "\n",
        "**プログラム言語->コンピュータが実行可能な形式への変換**  \n",
        "\n",
        "を指しますが，Kerasにおけるコンパイルは\n",
        "\n",
        "**訓練プロセスを作る**\n",
        "\n",
        "ことを指します．\n",
        "\n",
        "### オプティマイザ\n",
        "訓練を進める上での最適化アルゴリズムです．  \n",
        "今回はAdam（移動平均で振動を抑制するモーメンタム と 学習率を調整して振動を抑制するRMSPropの組み合わせ）を使用します．  \n",
        "\n",
        "### 損失関数（Loss）\n",
        "訓練中に導いたものと正解ラベルの差です．  \n",
        "今回は他クラス分類問題に使用するのに適した他クラス交差エントロピーを使用します．  \n",
        "\n",
        "### 評価関数（Metrics）\n",
        "モデルが適しているかを評価するための指標です．  \n",
        "今回は予測結果全体と答えがどれぐらい一致しているかを判断するAccuracyを用います．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2Y7orsfJKa9"
      },
      "source": [
        "# optimizerをAdamで学習率0.0005で宣言（学習率以外のパラメタ変更不要）\n",
        "opt = Adam(learning_rate=0.0005)\n",
        "# 損失関数を多クラス交差エントロピー（多クラス分類問題に良い），評価関数をaccuracy（とすると損失関数のテンソルから自動でcotagoricalに），optimizerを入れてコンパイル\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixrPSRdSpcz6"
      },
      "source": [
        "## Tensorboardの起動"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs1X6E2EOqep"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2-htqBOppQV"
      },
      "source": [
        "## モデルの訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQbHkTaicFMj"
      },
      "source": [
        "tf_callback = TensorBoard(log_dir=\"logs\", histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wntOrO_NDsgA"
      },
      "source": [
        "### バッチサイズ\n",
        "各訓練ステップでひとまとまりとして渡す観測数です．  \n",
        "小さいと細かい特徴を捉えられたり精度が上がる反面，局所的な観測に影響を受けてしまうことがあります．  \n",
        "大きいと平均化されますが，局所的な観測の影響は少なくなります．  \n",
        "今回は小さめの16にします．\n",
        "\n",
        "### エポック\n",
        "ネットワークに全トレーニングデータを渡す回数です．  \n",
        "今回は10回にしておきます．\n",
        "\n",
        "### シャッフル\n",
        "真のとき，各訓練ステップで訓練データからランダムに重複なく取り出します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l5_kCaOweJw"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=16, epochs=10, shuffle=True, validation_data = (x_test, y_test), callbacks=[tf_callback])\n",
        "# modelを保存する\n",
        "model.save('ImageClassifier.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQyvXPhDteyZ"
      },
      "source": [
        "## モデルの検証"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_4_Xvgx0sbq"
      },
      "source": [
        "### 保存したモデルの読み込み\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl5B5kYr0qcm"
      },
      "source": [
        "model = load_model('ImageClassifier.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEuirE8S07zy"
      },
      "source": [
        "### テストセットに対する評価\n",
        "引数はテスト用のデータセットです．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6Ba2rx4Sszj"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15KfRdp0FX_x"
      },
      "source": [
        "### 画像とともに表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYLQ9mpnE-Z8"
      },
      "source": [
        "# テストセットの予測を表示する\n",
        "CLASSES = np.array(['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'])\n",
        "# [10000, 10]それぞれの観測に対する10クラスの確率のベクトル\n",
        "preds = model.predict(x_test)\n",
        "# argmax関数で最後の次元の最大値のインデックスがCLASSES配列のインデックスとなる．predsは[10000, 1]\n",
        "preds_single = CLASSES[np.argmax(preds, axis = -1)]\n",
        "actual_single = CLASSES[np.argmax(y_test, axis = -1)]\n",
        "\n",
        "n_to_show = 10\n",
        "indices = np.random.choice(range(len(x_test)), n_to_show)\n",
        "\n",
        "fig = plt.figure(figsize=(15, 3))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "counter = 0\n",
        "correct = 0\n",
        "for i, idx in enumerate(indices):\n",
        "    img = x_test[idx]\n",
        "    ax = fig.add_subplot(1, n_to_show, i + 1)\n",
        "    ax.axis('off')\n",
        "    ax.text(0.5, -0.35, 'pred = ' + str(preds_single[idx]), fontsize = 10, ha = 'center', transform = ax.transAxes)\n",
        "    ax.text(0.5, -0.7, 'act = ' + str(actual_single[idx]), fontsize=10, ha='center', transform=ax.transAxes)\n",
        "    ax.imshow(img)\n",
        "    print(str(i) + ': pred = ' + str(preds_single[idx]))\n",
        "    print(str(i) + ': act = ' + str(actual_single[idx]))\n",
        "    if preds_single[idx] == actual_single[idx]:\n",
        "        correct += 1\n",
        "    counter += 1\n",
        "print('correct rate is: ' + str(100 * correct / counter))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBW2tBfAC1kM"
      },
      "source": [
        "# ONNXへ変換"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBuqBo2N2RD5"
      },
      "source": [
        "## ONNXとtf2onnxをインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EztwK0-b7iGM"
      },
      "source": [
        "!pip install onnx\n",
        "!pip install tf2onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZutEBJ-2F_I"
      },
      "source": [
        "## 変換用スクリプト使用のためレポジトリをクローン"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0eKAnKYHZc5"
      },
      "source": [
        "!git clone https://github.com/onnx/tensorflow-onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49fg8DtA1f8p"
      },
      "source": [
        "## TensorFlow saved modelとして保存\n",
        "ONNXへの変換はkeras2onnxよりtx2onnx経由のほうが成功します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "budTSB0xy33j"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = load_model('ImageClassifier.h5')\n",
        "tf.saved_model.save(model, 'tmp_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clGMTXAp1UkH"
      },
      "source": [
        "## 変換＋保存"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phs-hYafI4yA"
      },
      "source": [
        "!python -m tensorflow-onnx.tf2onnx.convert --saved-model tmp_model --output \"ImageClassifier.onnx\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}