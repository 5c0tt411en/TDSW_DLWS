{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TDSW_DLWS_DAY1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-PbhdwiCB_o"
      },
      "source": [
        "# 準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaPDl5KJiZUV"
      },
      "source": [
        "## GPUを使えるようにする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GHanLRUidlF"
      },
      "source": [
        "1. メニューから `Runtime>Change runtime type` を選択する\n",
        "2. Hardware acceleratorでGPUを選択する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6VCXIsBjfD5"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqGtrQT_21Cs"
      },
      "source": [
        "## Google driveのマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXOfM3dYJTDr"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJWlwoR3AB2F"
      },
      "source": [
        "## Google Drive上でのディレクトリ作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOryyrx5-rQp"
      },
      "source": [
        "コマンドは `% + コマンド` で実現していきます．\n",
        "\n",
        "Google Driveのルートディレクトリである　`/content/drive/MyDrive`  に移動します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-02BP0_gJnbP"
      },
      "source": [
        "%cd /content/drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8TWP6ihAAUI"
      },
      "source": [
        "```\n",
        "MyDrive\n",
        "|--TDSW_DLWS\n",
        "    |--ImageClassifier\n",
        "        |--models\n",
        "```\n",
        "という構造でディレクトリを作成します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KxMBs9mKPhk"
      },
      "source": [
        "%mkdir TDSW_DLWS TDSW_DLWS/ImageClassifier/ TDSW_DLWS/ImageClassifier/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E43aUZihA84Y"
      },
      "source": [
        "ディレクトリを移動します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLgRrzdJKVfg",
        "outputId": "1a7758ed-1831-402f-ea6a-2abf5fd1e9cf"
      },
      "source": [
        "%cd TDSW_DLWS/ImageClassifier/models"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/TDSW_DLWS/ImageClassifier/models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZHQUtQEBR8J"
      },
      "source": [
        "# 学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiPlG55VBpIe"
      },
      "source": [
        "## ライブラリのインポート\n",
        "必要なライブラリ，モジュールを読み込みます．  \n",
        "それぞれの機能については実際に使用する段階で説明します．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3i0WFLhTopj"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Input, Flatten, Conv2D, Dense, BatchNormalization, LeakyReLU, Dropout, Activation, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ducJEVoO5wRA"
      },
      "source": [
        "## データセットの読み込み＋前処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71kCUUrNNLT_"
      },
      "source": [
        "### CIFAR-10（画像とラベル）の読み込み\n",
        "CIFAR-10データセットを読み込みます．\n",
        "これは下の図のような60,000枚の32x32pxのRGB画像とそのラベル（どのクラスに属するか）のセットです．\n",
        "\n",
        "</br>\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1iHrBQSOBeOHNC9bMZc12IXhdtZk-ihM6\" width = 50%>\n",
        "\n",
        "</br>\n",
        "\n",
        "CIFAR-10などはKerasに同封されているためサクッと読み込めます．\n",
        "\n",
        "- x_train: 入力する訓練データ\n",
        "- x_test: テスト用データ\n",
        "- y_train: x_trainの各観測が属するクラス0 -- 9\n",
        "- y_test: x_testの各観測が属するクラス0 -- 9\n",
        "- cifar10.load_data(): データを読み込む関数\n",
        "\n",
        "データセットは訓練用とテスト用に分ける必要があります．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiAHp04jwI1A"
      },
      "source": [
        "NUM_CLASSES = 10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yB9ptk-60hY"
      },
      "source": [
        "print(x_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na2pAalN79hu"
      },
      "source": [
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHjYKFbW5kyi"
      },
      "source": [
        "### 0 - 255を0.0 - 1.0の32bit floatに変換\n",
        "ニューラルネットワークの入力は-1.0 -- 1.0で最も機能するため，割り算します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnF-bNXe4xTn"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss3SRcmf6tlI"
      },
      "source": [
        "### one-hotエンコーディング\n",
        "ラベルデータは，\n",
        "\n",
        "- 'airplane': 0\n",
        "- 'automobile': 1\n",
        "- 'bird': 2\n",
        "- 'cat': 3\n",
        "\n",
        "のようになっていますが，**クラス名と数字の大小は本来関係がありません**．  \n",
        "この大小関係を持ち込まないために，正解が1でそれ以外ゼロのベクトルに変更します．  \n",
        "ある画像のラベルが2番目（値は1）の場合:  \n",
        "`[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]`\n",
        "\n",
        "10クラスあるので，ベクトルの形状は`[50000, 1]`から`[50000, 10]`に変化します．  \n",
        "\n",
        "</br>\n",
        "\n",
        "関数はto_categorical(データ, クラス数)を使用します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TwXGwRD5b5d"
      },
      "source": [
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOHkkUI6mxQw"
      },
      "source": [
        "### データの水増し(今回は割愛)\n",
        "モデルの精度を高めるためにデータセットの画像に反転，回転，拡大縮小などの処理を加えてデータセットの数を増やします．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn5jwYJwo9_A"
      },
      "source": [
        "# データの水増し\n",
        "gen = ImageDataGenerator(rotation_range = 20, horizontal_flip = True, height_shift_range = 0.2, width_shift_range = 0.2,zoom_range = 0.2, channel_shift_range = 0.2)\n",
        "train_gen = gen.flow(x_train, y_train, batch_size=32)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQxzctq3m224"
      },
      "source": [
        "## アーキテクチャのセットアップ\n",
        "Sequentialモデルではなく，より自由度の高いFunctional APIにて設計していきます．  \n",
        "あまり記述量も変わらないので，最初からFunctional APIで実装していくことをおすすめします．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKW25kF0Cgy5"
      },
      "source": [
        "### 入力層\n",
        "入力層には任意の枚数の画像を渡します．  \n",
        "shapeは入力の次元数を示しています．  \n",
        "バッチサイズは任意の枚数であるため，指定する必要はありません．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3PLJJnSCffJ"
      },
      "source": [
        "input_layer = Input(shape = (32, 32, 3))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rQ20YR1L6H_"
      },
      "source": [
        "### 畳み込み層\n",
        "convolution layerを宣言  \n",
        "kernel_size: カーネル（フィルタ）の縦横幅  \n",
        "strides: 画像をスキャンするときのステップサイズ  \n",
        "padding: sameの場合，畳み込み時にできる元画像の空白をゼロで埋める  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ik8vJZ6L1fl"
      },
      "source": [
        "x = Conv2D(filters=32, kernel_size=3, strides=1, padding='same')(input_layer)\n",
        "# x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "\n",
        "# x = Conv2D(filters=32, kernel_size=3, strides=2, padding='same')(x)\n",
        "# x = BatchNormalization()(x)\n",
        "# x = LeakyReLU()(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "x = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(x)\n",
        "# x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "\n",
        "# x = Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(x)\n",
        "# x = BatchNormalization()(x)\n",
        "# x = LeakyReLU()(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# 次のDense層の入力が１次元配列のためFlatten層でベクトル化\n",
        "# 3072 = 32 * 32 * 3\n",
        "x = Flatten()(x)\n",
        "\n",
        "# 前の層と密結合したノードを無限に持てるDense層\n",
        "# 活性化関数LeakyReLU．\n",
        "# Dropoutの引数はどれだけの割合ゼロするか\n",
        "# x = Dense(128)(x)\n",
        "# x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = Dropout(rate=0.50)(x)\n",
        "\n",
        "x = Dense(NUM_CLASSES)(x)\n",
        "\n",
        "# 出力層を活性化関数softmax（総和１，他クラス分類問題に良い）\n",
        "output_layer = Activation('softmax')(x)\n",
        "\n",
        "# モデルとして宣言\n",
        "model = Model(input_layer, output_layer)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgEX0yFHn8lD"
      },
      "source": [
        "## モデルのコンパイル\n",
        "普段聞くコンパイルは，  \n",
        "\n",
        "**プログラム言語->コンピュータが実行可能な形式への変換**  \n",
        "\n",
        "を指しますが，Kerasにおけるコンパイルは\n",
        "\n",
        "**訓練プロセスを作る**\n",
        "\n",
        "ことを指します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2Y7orsfJKa9"
      },
      "source": [
        "# optimizerをAdamで学習率0.0005で宣言（学習率以外のパラメタ変更不要）\n",
        "opt = Adam(learning_rate=0.0005)\n",
        "# 損失関数を多クラス交差エントロピー（多クラス分類問題に良い），評価関数をaccuracy（とすると損失関数のテンソルから自動でcotagoricalに），optimizerを入れてコンパイル\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixrPSRdSpcz6"
      },
      "source": [
        "## Tensorboardの起動"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs1X6E2EOqep"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2-htqBOppQV"
      },
      "source": [
        "## モデルの訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQbHkTaicFMj"
      },
      "source": [
        "tf_callback = TensorBoard(log_dir=\"logs\", histogram_freq=1)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l5_kCaOweJw"
      },
      "source": [
        "# batch_size: 各訓練ステップでひとまとまりとして渡す観測数\n",
        "# epochs: ネットワークに全トレーニングデータを渡す回数\n",
        "# shuffle: 各訓練ステップで訓練データからランダムに重複なく取り出す\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=20, shuffle=True, validation_data = (x_test, y_test), callbacks=[tf_callback])\n",
        "# modelを保存する\n",
        "model.save('ImageClassifier.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQyvXPhDteyZ"
      },
      "source": [
        "## モデルの検証"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6Ba2rx4Sszj"
      },
      "source": [
        "#modelへ保存データを読み込み\n",
        "model = load_model('ImageClassifier.h5')\n",
        "\n",
        "######### モデルを評価する\n",
        "# テストセットに対する評価を行なう\n",
        "model.evaluate(x_test, y_test)\n",
        "\n",
        "# テストセットの予測を表示する\n",
        "CLASSES = np.array(['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'])\n",
        "# [10000, 10]それぞれの観測に対する10クラスの確率のベクトル\n",
        "preds = model.predict(x_test)\n",
        "# argmax関数で最後の次元の最大値のインデックスがCLASSES配列のインデックスとなる．predsは[10000, 1]\n",
        "preds_single = CLASSES[np.argmax(preds, axis = -1)]\n",
        "actual_single = CLASSES[np.argmax(y_test, axis = -1)]\n",
        "\n",
        "n_to_show = 10\n",
        "indices = np.random.choice(range(len(x_test)), n_to_show)\n",
        "\n",
        "fig = plt.figure(figsize=(15, 3))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "counter = 0\n",
        "correct = 0\n",
        "for i, idx in enumerate(indices):\n",
        "    img = x_test[idx]\n",
        "    ax = fig.add_subplot(1, n_to_show, i + 1)\n",
        "    ax.axis('off')\n",
        "    ax.text(0.5, -0.35, 'pred = ' + str(preds_single[idx]), fontsize = 10, ha = 'center', transform = ax.transAxes)\n",
        "    ax.text(0.5, -0.7, 'act = ' + str(actual_single[idx]), fontsize=10, ha='center', transform=ax.transAxes)\n",
        "    ax.imshow(img)\n",
        "    print(str(i) + ': pred = ' + str(preds_single[idx]))\n",
        "    print(str(i) + ': act = ' + str(actual_single[idx]))\n",
        "    if preds_single[idx] == actual_single[idx]:\n",
        "        correct += 1\n",
        "    counter += 1\n",
        "print('correct rate is: ' + str(100 * correct / counter))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBW2tBfAC1kM"
      },
      "source": [
        "# ONNXへ変換"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EztwK0-b7iGM"
      },
      "source": [
        "!pip install onnx\n",
        "!pip install tf2onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0eKAnKYHZc5"
      },
      "source": [
        "!git clone https://github.com/onnx/tensorflow-onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "budTSB0xy33j"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = load_model('ImageClassifier.h5')\n",
        "tf.saved_model.save(model, 'tmp_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phs-hYafI4yA"
      },
      "source": [
        "!python -m tensorflow-onnx.tf2onnx.convert --saved-model tmp_model --output \"ImageClassifier.onnx\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}