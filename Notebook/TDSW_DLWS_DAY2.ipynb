{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TDSW_DLWS_DAY2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-PbhdwiCB_o"
      },
      "source": [
        "# 準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaPDl5KJiZUV"
      },
      "source": [
        "## GPUを使えるようにする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GHanLRUidlF"
      },
      "source": [
        "1. メニューから `Runtime>Change runtime type` を選択する\n",
        "2. Hardware acceleratorでGPUを選択する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6VCXIsBjfD5"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqGtrQT_21Cs"
      },
      "source": [
        "## Google driveのマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXOfM3dYJTDr"
      },
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJWlwoR3AB2F"
      },
      "source": [
        "## Google Drive上でのディレクトリ作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOryyrx5-rQp"
      },
      "source": [
        "コマンドは `% + コマンド` で実現していきます．\n",
        "\n",
        "Google Driveのルートディレクトリである　`/content/drive/MyDrive`  に移動します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-02BP0_gJnbP"
      },
      "source": [
        "%cd /content/drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8TWP6ihAAUI"
      },
      "source": [
        "```\n",
        "MyDrive\n",
        "|--TDSW_DLWS\n",
        "    |--VAE\n",
        "        |--models\n",
        "```\n",
        "という構造でディレクトリを作成します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KxMBs9mKPhk"
      },
      "source": [
        "%mkdir TDSW_DLWS/AE/ TDSW_DLWS/AE/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E43aUZihA84Y"
      },
      "source": [
        "ディレクトリを移動します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLgRrzdJKVfg"
      },
      "source": [
        "%cd TDSW_DLWS/AE/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZHQUtQEBR8J"
      },
      "source": [
        "# 学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiPlG55VBpIe"
      },
      "source": [
        "## ライブラリのインポート\n",
        "必要なライブラリ，モジュールを読み込みます．  \n",
        "それぞれの機能については実際に使用する段階で説明します．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3i0WFLhTopj"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ducJEVoO5wRA"
      },
      "source": [
        "## データセットの読み込み＋前処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71kCUUrNNLT_"
      },
      "source": [
        "### MNIST（画像とラベル）の読み込み\n",
        "CIFAR-10データセットを読み込みます．\n",
        "これは下の図のような70,000枚(学習用60,000 + 検証用10,000)の28x28pxのGRAYSCALE画像とそのラベル（どのクラスに属するか）のセットです．\n",
        "\n",
        "</br>\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1G-tfBSJ76-Ug0F-DhGvUUh_Lj10OpgFa\" width = 50%>\n",
        "\n",
        "</br>\n",
        "\n",
        "MNISTはCIFAR-10などと同じくKerasに同封されているためサクッと読み込めます．\n",
        "\n",
        "- x_train: 入力する訓練データ\n",
        "- x_test: テスト用データ\n",
        "- y_train: x_trainの各観測が属するクラス0 -- 9\n",
        "- y_test: x_testの各観測が属するクラス0 -- 9\n",
        "- mnist.load_data(): データを読み込む関数\n",
        "\n",
        "データセットは訓練用とテスト用に分ける必要があります．\n",
        "\n",
        "訓練時には見せず，**未知のデータに対して推論できているかどうか確かめる**ためです．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiAHp04jwI1A"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yB9ptk-60hY"
      },
      "source": [
        "print(x_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na2pAalN79hu"
      },
      "source": [
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### x_trainを保存しておく\n",
        "後ほどTouchDesigner側でのプロットで使用するため，x_trainを保存しておきます．"
      ],
      "metadata": {
        "id": "fnRqr4BjGQiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('mnist_x_train', x_train)\n",
        "np.save('mnist_x_test', x_test)"
      ],
      "metadata": {
        "id": "EuC57W7LF8P4"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHjYKFbW5kyi"
      },
      "source": [
        "### 0 - 255を0.0 - 1.0の32bit floatに変換\n",
        "ニューラルネットワークの入力は-1.0 -- 1.0で最も機能するため，割り算します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnF-bNXe4xTn"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255."
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss3SRcmf6tlI"
      },
      "source": [
        "### 平滑化\n",
        "reshape関数で`[60000, 28, 28]`から`[60000, 784]`に平滑化しておきます．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TwXGwRD5b5d"
      },
      "source": [
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQxzctq3m224"
      },
      "source": [
        "## アーキテクチャのセットアップ\n",
        "Sequentialモデルではなく，より自由度の高いFunctional APIにて設計していきます．  \n",
        "あまり記述量も変わらないので，最初からFunctional APIで実装していくことをおすすめします．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rQ20YR1L6H_"
      },
      "source": [
        "### Encoder\n",
        "圧縮された潜在表現を得るEncoderを作ります．\n",
        "\n",
        "### 入力層\n",
        "入力層には任意の枚数の画像を渡します．  \n",
        "shapeは入力の次元数を示しています．  \n",
        "実際の入力はもう１次元あるのですが，バッチサイズは任意の枚数であるため，指定していません．  \n",
        "\n",
        "### 全結合層\n",
        "前の層と密結合したノードを指定の数持てます．  \n",
        "今回は 784->256->64->16->2 と，次元を圧縮していきます．\n",
        "\n",
        "### 活性化関数\n",
        "活性化関数はニューラルネットが複雑な機能を学習し，単なる線形な組み合わせを出力しないように重みなどに掛け合わされて伝搬の具合に変化を与えます．  \n",
        "今回はゼロ以下をすべてゼロにするReLUを使用します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_NJiAiwq6gM"
      },
      "source": [
        "encoding_dim = 2\n",
        "\n",
        "encoder_input_layer = Input(shape=(784,), name='encoder_input')\n",
        "e = Dense(256, activation='relu')(encoder_input_layer)\n",
        "e = Dense(64, activation='relu')(e)\n",
        "e = Dense(16, activation='relu')(e)\n",
        "encoder_output_layer = Dense(encoding_dim, activation='relu', name='encoder_output')(e)\n",
        "\n",
        "encoder = Model(encoder_input_layer, encoder_output_layer, name='encoder')"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### エンコーダの確認"
      ],
      "metadata": {
        "id": "mpDgoEzFRgjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.summary()"
      ],
      "metadata": {
        "id": "PULzSfVAnTdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDeH3OSG56Us"
      },
      "source": [
        "### Encoder\n",
        "復元するDecoderを作ります．\n",
        "\n",
        "### 全結合層\n",
        "前の層と密結合したノードを指定の数持てます．  \n",
        "今回は Encoderと逆の2->16->64->256->784 と，次元を復元していきます．\n",
        "\n",
        "### 活性化関数\n",
        "活性化関数はニューラルネットが複雑な機能を学習し，単なる線形な組み合わせを出力しないように重みなどに掛け合わされて伝搬の具合に変化を与えます．  \n",
        "今回はゼロ未満をすべてゼロにするReLUを使用します．  \n",
        "また，出力層ではsigmoidを使用します．  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ik8vJZ6L1fl"
      },
      "source": [
        "decoder_input_layer = Input(shape=(encoding_dim,), name='decoder_input')\n",
        "d = Dense(16, activation='relu')(decoder_input_layer)\n",
        "d = Dense(64, activation='relu')(d)\n",
        "d = Dense(256, activation='relu')(d)\n",
        "decoder_output_layer = Dense(784, activation='sigmoid', name='decoder_output')(d)\n",
        "\n",
        "decoder = Model(decoder_input_layer, decoder_output_layer, name='decoder')"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder.summary()"
      ],
      "metadata": {
        "id": "JFargp2DnV3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EncoderとDecoderを連結\n",
        "EncoderとDecoderを同時に訓練するため，連結したネットワークにする必要があります．  \n",
        "Kerasではどの出力から連結するのか指定します．"
      ],
      "metadata": {
        "id": "oLRqlBF2geni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ae_input_layer = encoder_input_layer\n",
        "ae_output_layer = decoder(encoder(encoder_input_layer))"
      ],
      "metadata": {
        "id": "aQAWuyCggcjX"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EncoderとDecoderをあわせたAutoEncoderとして宣言"
      ],
      "metadata": {
        "id": "7OUwFNBteNWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = Model(ae_input_layer, ae_output_layer, name='autoencoder')"
      ],
      "metadata": {
        "id": "PaytXDQdzhFg"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JCe7xb__-Zg"
      },
      "source": [
        "### アーキテクチャの確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VJewd1V_9is"
      },
      "source": [
        "autoencoder.summary()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgEX0yFHn8lD"
      },
      "source": [
        "## モデルのコンパイル\n",
        "普段聞くコンパイルは，  \n",
        "\n",
        "**プログラム言語->コンピュータが実行可能な形式への変換**  \n",
        "\n",
        "を指しますが，Kerasにおけるコンパイルは\n",
        "\n",
        "**訓練プロセスを作る**\n",
        "\n",
        "ことを指します．\n",
        "\n",
        "### オプティマイザ\n",
        "訓練を進める上での最適化アルゴリズムです．  \n",
        "今回はAdam（移動平均で振動を抑制するモーメンタム と 学習率を調整して振動を抑制するRMSPropの組み合わせ）を使用します．  \n",
        "\n",
        "### 損失関数（Loss）\n",
        "訓練中に導いたものと正解の差です．  \n",
        "今回は入力画像と出力画像のピクセル値に対して２値交差エントロピーを使用します．  \n",
        "２値交差エントロピーは大きく間違った極端な予想に対して誤差を大きく返します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2Y7orsfJKa9"
      },
      "source": [
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixrPSRdSpcz6"
      },
      "source": [
        "## Tensorboardの起動"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs1X6E2EOqep"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2-htqBOppQV"
      },
      "source": [
        "## モデルの訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQbHkTaicFMj"
      },
      "source": [
        "tf_callback = TensorBoard(log_dir=\"logs\", histogram_freq=1)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wntOrO_NDsgA"
      },
      "source": [
        "### バッチサイズ\n",
        "各訓練ステップでひとまとまりとして渡す観測数です．  \n",
        "小さいと細かい特徴を捉えられたり精度が上がる反面，局所的な観測に影響を受けてしまうことがあります．  \n",
        "大きいと平均化されますが，局所的な観測の影響は少なくなります．  \n",
        "今回は256にします．\n",
        "\n",
        "### エポック\n",
        "ネットワークに全トレーニングデータを渡す回数です．  \n",
        "今回は100回にしておきます．\n",
        "\n",
        "### シャッフル\n",
        "真のとき，各訓練ステップで訓練データからランダムに重複なく取り出します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l5_kCaOweJw"
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=100,    \n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                callbacks=[tf_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 訓練したモデルの保存"
      ],
      "metadata": {
        "id": "UK2oFNGbyHmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.save('AE.h5')"
      ],
      "metadata": {
        "id": "BzsHfgb70aIi"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 訓練後のEncoderを抽出\n",
        "訓練後の重みを含んだモデル全体からEncoderまでを取り出します．\n",
        "入力と出力の層を指定することで抽出できます．"
      ],
      "metadata": {
        "id": "VGc990IYyMPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_ae = Model(autoencoder.input, autoencoder.get_layer('encoder').output)"
      ],
      "metadata": {
        "id": "hO5WE28AqbBk"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoderのコンパイル"
      ],
      "metadata": {
        "id": "4bVU3XpHzJBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_ae.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "syE_WXiDzpDK"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enocoderの保存"
      ],
      "metadata": {
        "id": "lFuwdPGRzMiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_ae.save('AE_encoder.h5')"
      ],
      "metadata": {
        "id": "aSHUH70PrzBh"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 訓練後のDecoderを抽出\n",
        "訓練後の重みを含んだモデル全体からDecoderまでを取り出します．\n",
        "入力と出力の層を指定することで抽出できます．"
      ],
      "metadata": {
        "id": "Y4CGJHpMzWQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_ae = Model(autoencoder.get_layer('decoder').input, autoencoder.get_layer('decoder').output)"
      ],
      "metadata": {
        "id": "t1KQnjsVxHZ0"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoderのコンパイル"
      ],
      "metadata": {
        "id": "KWD6ibIv0Ot1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_ae.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "fHng4Jjuzqwc"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoderの保存"
      ],
      "metadata": {
        "id": "RHh2jyEA0QL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_ae.save('AE_decoder.h5')"
      ],
      "metadata": {
        "id": "NG5ndU08xYej"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQyvXPhDteyZ"
      },
      "source": [
        "## モデルの検証"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_4_Xvgx0sbq"
      },
      "source": [
        "### 保存したモデルの読み込み\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl5B5kYr0qcm"
      },
      "source": [
        "model = load_model('AE.h5')"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEuirE8S07zy"
      },
      "source": [
        "### テストセットに対する評価\n",
        "引数はテスト用のデータセットです．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6Ba2rx4Sszj"
      },
      "source": [
        "model.evaluate(x_test, x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15KfRdp0FX_x"
      },
      "source": [
        "### 画像とともに表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYLQ9mpnE-Z8"
      },
      "source": [
        "decoded_imgs = model.predict(x_test)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(10, 2))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(2, n, i+1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    ax = plt.subplot(2, n, i+1+n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBW2tBfAC1kM"
      },
      "source": [
        "# ONNXへ変換"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBuqBo2N2RD5"
      },
      "source": [
        "## ONNXとtf2onnxをインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EztwK0-b7iGM"
      },
      "source": [
        "!pip install onnx\n",
        "!pip install tf2onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZutEBJ-2F_I"
      },
      "source": [
        "## 変換用スクリプト使用のためレポジトリをクローン"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0eKAnKYHZc5"
      },
      "source": [
        "!git clone https://github.com/onnx/tensorflow-onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49fg8DtA1f8p"
      },
      "source": [
        "## TensorFlow saved modelとして保存\n",
        "ONNXへの変換はkeras2onnxよりtx2onnx経由のほうが成功します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "budTSB0xy33j"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = load_model('AE.h5')\n",
        "tf.saved_model.save(model, 'tmp_model_AE')\n",
        "model = load_model('AE_encoder.h5')\n",
        "tf.saved_model.save(model, 'tmp_model_AE_encoder')\n",
        "model = load_model('AE_decoder.h5')\n",
        "tf.saved_model.save(model, 'tmp_model_AE_decoder')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clGMTXAp1UkH"
      },
      "source": [
        "## 変換＋保存"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phs-hYafI4yA"
      },
      "source": [
        "!python -m tensorflow-onnx.tf2onnx.convert --saved-model tmp_model_AE --output \"AE.onnx\"\n",
        "!python -m tensorflow-onnx.tf2onnx.convert --saved-model tmp_model_AE_encoder --output \"AE_encoder.onnx\"\n",
        "!python -m tensorflow-onnx.tf2onnx.convert --saved-model tmp_model_AE_decoder --output \"AE_decoder.onnx\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}